{"cells":[{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["import torchvision\n","import torchvision.datasets as dset\n","import torchvision.transforms as transforms\n","from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n","from torch.utils.data import DataLoader,Dataset\n","import torchvision.utils\n","import numpy as np\n","import random\n","from PIL import Image\n","import PIL.ImageOps\n","import torch\n","from torch.autograd import Variable\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from tqdm.autonotebook import tqdm as tqdm_jupyter\n","from tqdm import tqdm as tqdm_bash\n","import inspect\n","import os\n","import time\n","\n",""]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["# Adapted from https://github.com/harveyslash/Facial-Similarity-with-Siamese-Networks-in-Pytorch/blob/master/Siamese-networks-medium.ipynb\n","class SiameseDataset(Dataset):\n","    def __init__(self,imageFolderDataset,transform=None):\n","        self.imageFolderDataset = imageFolderDataset    \n","        self.transform = transform\n","        \n","    def __getitem__(self,index):\n","        img0_tuple = random.choice(self.imageFolderDataset.imgs)\n","        same_class = random.randint(0,1) \n","        if same_class:\n","            while True:\n","                img1_tuple = random.choice(self.imageFolderDataset.imgs) # Find a better way to do this\n","                if img0_tuple[1]==img1_tuple[1]:\n","                    break\n","        else:\n","            while True:\n","                img1_tuple = random.choice(self.imageFolderDataset.imgs) # This too\n","                if img0_tuple[1] !=img1_tuple[1]:\n","                    break\n","\n","        img0 = Image.open(img0_tuple[0])\n","        img1 = Image.open(img1_tuple[0])\n","        img0 = img0.convert(\"L\")\n","        img1 = img1.convert(\"L\")\n","\n","        if self.transform is not None:\n","            img0 = self.transform(img0)\n","            img1 = self.transform(img1)\n","        \n","        return img0, img1 , torch.from_numpy(np.array([int(img1_tuple[1]!=img0_tuple[1])],dtype=np.float32))\n","    \n","    def __len__(self):\n","        return len(self.imageFolderDataset.imgs)\n","\n","class SiameseNetwork(nn.Module):\n","    def __init__(self):\n","        super(SiameseNetwork, self).__init__()\n","        self.cnn1 = nn.Sequential(\n","            nn.ReflectionPad2d(1),\n","            nn.Conv2d(1, 4, kernel_size=3),\n","            nn.ReLU(inplace=True),\n","            nn.BatchNorm2d(4),\n","            \n","            nn.ReflectionPad2d(1),\n","            nn.Conv2d(4, 8, kernel_size=3),\n","            nn.ReLU(inplace=True),\n","            nn.BatchNorm2d(8),\n","\n","\n","            nn.ReflectionPad2d(1),\n","            nn.Conv2d(8, 8, kernel_size=3),\n","            nn.ReLU(inplace=True),\n","            nn.BatchNorm2d(8),\n","        )\n","\n","        self.fc1 = nn.Sequential(\n","            nn.Linear(8*100*100, 500),\n","            nn.ReLU(inplace=True),\n","\n","            nn.Linear(500, 500),\n","            nn.ReLU(inplace=True),\n","\n","            nn.Linear(500, 5))\n","\n","    def forward_once(self, x):\n","        output = self.cnn1(x)\n","        output = output.view(output.size()[0], -1)\n","        output = self.fc1(output)\n","        return output\n","\n","    def forward(self, input1, input2):\n","        output1 = self.forward_once(input1)\n","        output2 = self.forward_once(input2)\n","        return output1, output2\n","\n",""]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["class ContrastiveLoss(torch.nn.Module):\n","    \"\"\"\n","    Contrastive loss function.\n","    Based on: http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n","    \"\"\"\n","\n","    def __init__(self, margin=2.0):\n","        super(ContrastiveLoss, self).__init__()\n","        self.margin = margin\n","\n","    def forward(self, output1, output2, label):\n","        euclidean_distance = F.pairwise_distance(output1, output2, keepdim = True)\n","        contrastive_loss = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +\n","                                      (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n","        return contrastive_loss\n","\n",""]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"CUDA availability:True\n"}],"source":["pbar_type = \"jupyter\" # \"bash\"\n","epochs = 20\n","batch_size = 64\n","\n","model_name = \"skw.base_cnn.v1\"\n","model_path = os.path.join(\"models\",model_name+\".ep_\"+str(epochs))\n","if not os.path.exists(model_path):\n","    os.makedirs(model_path)\n","\n","root_dir = \"data\"\n","train_dir = os.path.join(root_dir,\"train\")\n","test_dir = os.path.join(root_dir,\"test\")\n","\n","im_train_dset = dset.ImageFolder(root=train_dir)\n","im_test_dset = dset.ImageFolder(root=test_dir)\n","transformation = transforms.Compose([transforms.Resize((100,100)),\n","                                     transforms.ToTensor()])\n","train_siamese_dset = SiameseDataset(imageFolderDataset=im_train_dset, transform=transformation)\n","val_siamese_dset = SiameseDataset(imageFolderDataset=im_test_dset, transform=transformation)\n","train_loader = DataLoader(train_siamese_dset,shuffle=True,num_workers=0,batch_size=batch_size)\n","val_loader = DataLoader(val_siamese_dset,shuffle=True,num_workers=0,batch_size=batch_size)\n","\n","loss_function = ContrastiveLoss()\n","\n","optimizer = optim.Adadelta(model.parameters())\n","print(\"CUDA availability:\",torch.cuda.is_available())\n","\n",""]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"CUDA availability:True\n"}],"source":["pbar_type = \"bash\"\n","epochs = 20\n","batch_size = 64\n","\n","model_name = \"skw.base_cnn.v1\"\n","model_path = os.path.join(\"models\",model_name+\".ep_\"+str(epochs))\n","if not os.path.exists(model_path):\n","    os.makedirs(model_path)\n","\n","root_dir = \"data\"\n","train_dir = os.path.join(root_dir,\"train\")\n","test_dir = os.path.join(root_dir,\"test\")\n","\n","im_train_dset = dset.ImageFolder(root=train_dir)\n","im_test_dset = dset.ImageFolder(root=test_dir)\n","transformation = transforms.Compose([transforms.Resize((100,100)),\n","                                     transforms.ToTensor()])\n","train_siamese_dset = SiameseDataset(imageFolderDataset=im_train_dset, transform=transformation)\n","val_siamese_dset = SiameseDataset(imageFolderDataset=im_test_dset, transform=transformation)\n","train_loader = DataLoader(train_siamese_dset,shuffle=True,num_workers=0,batch_size=batch_size)\n","val_loader = DataLoader(val_siamese_dset,shuffle=True,num_workers=0,batch_size=batch_size)\n","\n","loss_function = ContrastiveLoss()\n","\n","optimizer = optim.Adadelta(model.parameters())\n","print(\"CUDA availability:\",torch.cuda.is_available())\n","\n",""]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":"Loss: 1.7974: 100%|██████████| 5356/5356 [1:55:39<00:00,  1.16 batches/s]\nEpoch 1/20, training loss: 1.7973654339725709\nSaving new best model at epoch 0\nLoss: 1.7888: 100%|██████████| 5356/5356 [1:34:10<00:00,  1.23 batches/s]\nEpoch 2/20, training loss: 1.7888250851515428\nSaving new best model at epoch 1\nLoss: 1.7919: 100%|██████████| 5356/5356 [1:37:19<00:00,  1.02s/ batches]\nEpoch 3/20, training loss: 1.7918978706948163\nLoss: 1.7913: 100%|██████████| 5356/5356 [1:40:18<00:00,  1.16 batches/s]\nEpoch 4/20, training loss: 1.7913251741106961\nLoss: 1.7883: 100%|██████████| 5356/5356 [1:31:21<00:00,  1.21 batches/s]\nEpoch 5/20, training loss: 1.7882987402373949\nSaving new best model at epoch 4\nLoss: 1.7913: 100%|██████████| 5356/5356 [1:30:22<00:00,  1.28 batches/s]\nEpoch 6/20, training loss: 1.7913419282240508\nLoss: 1.7917: 100%|██████████| 5356/5356 [1:30:03<00:00,  1.26 batches/s]\nEpoch 7/20, training loss: 1.7916959938026347\nLoss: 1.7910: 100%|██████████| 5356/5356 [1:30:04<00:00,  1.32 batches/s]\nEpoch 8/20, training loss: 1.7910339477304382\nLoss: 1.7875: 100%|██████████| 5356/5356 [1:30:00<00:00,  1.29 batches/s]\nEpoch 9/20, training loss: 1.7875081353039775\nSaving new best model at epoch 8\nLoss: 1.7861: 100%|██████████| 5356/5356 [1:30:06<00:00,  1.31 batches/s]\nEpoch 10/20, training loss: 1.7860591027877328\nSaving new best model at epoch 9\nLoss: 1.7932: 100%|██████████| 5356/5356 [1:30:03<00:00,  1.25 batches/s]\nEpoch 11/20, training loss: 1.793213068481877\nLoss: 1.7918: 100%|██████████| 5356/5356 [1:30:20<00:00,  1.27 batches/s]\nEpoch 12/20, training loss: 1.791838269789242\nLoss: 1.7949: 100%|██████████| 5356/5356 [1:46:09<00:00,  1.14 batches/s]\nEpoch 13/20, training loss: 1.7948751736257038\nLoss: 1.7897: 100%|██████████| 5356/5356 [1:35:22<00:00,  1.28 batches/s]\nEpoch 14/20, training loss: 1.7896794094533686\nLoss: 1.7887: 100%|██████████| 5356/5356 [1:30:49<00:00,  1.32 batches/s]\nEpoch 15/20, training loss: 1.7887180065423183\nLoss: 1.7910: 100%|██████████| 5356/5356 [1:30:18<00:00,  1.31 batches/s]\nEpoch 16/20, training loss: 1.790961633953165\nLoss: 1.7937: 100%|██████████| 5356/5356 [1:30:08<00:00,  1.26 batches/s]\nEpoch 17/20, training loss: 1.7936571353713997\nLoss: 1.7912: 100%|██████████| 5356/5356 [1:30:16<00:00,  1.10 batches/s]\nEpoch 18/20, training loss: 1.7912113930059066\nLoss: 1.7901: 100%|██████████| 5356/5356 [1:44:19<00:00,  1.18 batches/s]\nEpoch 19/20, training loss: 1.7900658123879578\nLoss: 1.7901: 100%|██████████| 5356/5356 [1:39:09<00:00,  1.13 batches/s]\nEpoch 20/20, training loss: 1.7900754977421052\nTraining time: 113810.65480422974s\n"}],"source":["start_ts = time.time()\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","losses = []\n","batches = len(train_loader)\n","val_batches = len(val_loader)\n","best_loss = 0\n","\n","model = SiameseNetwork().cuda()\n","\n","for epoch in range(epochs):\n","    total_loss = 0\n","    \n","    progress = None\n","    \n","    if pbar_type == \"bash\":\n","        progress = tqdm_bash(enumerate(train_loader,0), total=batches, unit=\" batches\", desc=\"Loss: \", position=0, leave=True)\n","    if pbar_type == \"jupyter\":\n","        progress = tqdm_jupyter(enumerate(train_loader,0), total=batches, unit=\" batches\", desc=\"Loss: \")\n","    \n","    model.train()\n","    \n","    for i,data in progress:\n","        img0, img1 , label = data\n","        img0, img1 , label = img0.cuda(), img1.cuda() , label.cuda()\n","        optimizer.zero_grad()\n","        output1, output2 = model(img0,img1)\n","        loss = loss_function(output1,output2,label)\n","        loss.backward()\n","        optimizer.step()\n","\n","        current_loss = loss.item()\n","        total_loss += current_loss\n","\n","        progress.set_description(\"Loss: {:.4f}\".format(total_loss/(i+1)))\n","    \n","    if torch.cuda.is_available():\n","        torch.cuda.empty_cache()\n","    \n","    curr_loss = total_loss/batches\n","    print(f\"Epoch {epoch+1}/{epochs}, training loss: {curr_loss}\")\n","          \n","    torch.save(model.state_dict(),os.path.join(model_path,\"epoch_\"+str(epoch)+\".pt\"))\n","    if (curr_loss < best_loss) or (best_loss == 0):\n","        best_loss = curr_loss\n","        print(\"Saving new best model at epoch {}\".format(epoch))\n","        torch.save(model.state_dict(),os.path.join(model_path,\"best.pt\"))\n","        \n","print(f\"Training time: {time.time()-start_ts}s\")\n","\n",""]}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}